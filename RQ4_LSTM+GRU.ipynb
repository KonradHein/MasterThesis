{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6fc8e-5f76-4d60-8e43-d6003fbd3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef3936-f7cf-4fa5-9695-9b6e64a6c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_users = [14995, 15044, 15051, 15052, 15110, 15115, 15151, 15159, 15170, 15171, 15173,\n",
    "                15208, 15241, 15258, 15280, 15335, 15405, 15419, 15445, 15448, 15482, 15510,\n",
    "                15588, 15729, 18001, 23737, 23743, 23753, 23756, 23768, 23769, 23770, 23785,\n",
    "                23787, 23800, 23829, 23867, 23871, 23875, 23878, 23881, 23883, 23889, 23893,\n",
    "                23897, 23906, 23913, 23914, 23915, 23919, 23921, 23924, 23926, 23935, 23936,\n",
    "                23961, 23983, 24030, 24039, 24040, 24079, 24109, 24120, 24124, 24127, 24167,\n",
    "                24185, 24193, 24195, 24196, 24197, 24198, 24204, 24207, 24212, 24225, 24226,\n",
    "                24227, 24235, 24246, 24248, 24324, 24346, 24350, 24461, 24467, 25163, 25164,\n",
    "                25169, 25170, 25171, 25174, 25175, 25178, 25180, 25189, 25250, 25461, 25522,\n",
    "                24081, 24203, 24249, 24612, 25498]\n",
    "lookback_ranges = [5, 10, 20]\n",
    "neurons = [64, 128, 256]\n",
    "batch_sizes = [64, 128, 256]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5d5b2-ab71-4893-a620-b7ce63da64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine split\n",
    "def splits(dataset):\n",
    "    instances_256 = len(dataset)/256\n",
    "    train_split = round(instances_256*0.8)*256\n",
    "    val_split = round(instances_256*0.9)*256\n",
    "    return train_split, val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac329f-d22a-4069-93fc-d5d3dc7b48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=5):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), :-1]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, -1])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801589cd-ad81-4431-a27d-183d20371187",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "cols = ['user', 'user_length', 'train_length', 'val_length', 'test_length']\n",
    "for user in lst_users1:\n",
    "    print(user)\n",
    "    out = [user]\n",
    "\n",
    "    dataframe = pd.read_pickle('Users_prepped/All/filtered/{}_final'.format(str(user)))\n",
    "    dataframe = dataframe[list(dataframe.columns)[1:]]\n",
    "    cols2 = [col for col in dataframe.columns if col != 'battery']\n",
    "    dataframe = dataframe[cols2]\n",
    "    dataset = dataframe.values\n",
    "    dataset = dataset.astype('float32')\n",
    "    \n",
    "    #Scale Features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    arrX = dataset[:, :-1]\n",
    "    arrY = dataset[:, -1]\n",
    "    arrY = arrY.reshape(arrY.shape[0], 1)\n",
    "    arrX = scaler.fit_transform(arrX)\n",
    "    dataset = np.concatenate((arrX, arrY), axis = 1)\n",
    "    \n",
    "    #split dataset\n",
    "    train_split, val_split = splits(dataset)\n",
    "    data_train = dataset[:train_split]\n",
    "    data_val = dataset[train_split:val_split]\n",
    "    data_test = dataset[val_split:]\n",
    "    \n",
    "    out.append(dataset.shape[0])\n",
    "    out.append(data_train.shape[0])\n",
    "    out.append(data_val.shape[0])\n",
    "    out.append(data_test.shape[0])\n",
    "    \n",
    "    if count == 0:\n",
    "        print(dataset.shape[0])\n",
    "        print(data_train.shape[0])\n",
    "        print(data_val.shape[0])\n",
    "        print(data_test.shape[0])\n",
    "    \n",
    "    for lookback_range in lookback_ranges:\n",
    "        #reshape into X=t and Y=t+1\n",
    "        trainX, trainY = create_dataset(data_train, lookback_range)\n",
    "        valX, valY = create_dataset(data_val, lookback_range)\n",
    "        testX, testY = create_dataset(data_test, lookback_range)\n",
    "        for n in neurons:\n",
    "            for batch_size in batch_sizes:\n",
    "                print('LookBack: {}, Neurons: {}, Batch_size:{}'.format(lookback_range, n, batch_size))\n",
    "                \n",
    "                model = Sequential()\n",
    "                model.add(LSTM(n, input_shape=trainX.shape[1:], return_sequences = False, dropout =0.4))\n",
    "                model.add(Dense(1))\n",
    "                model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "                \n",
    "                es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, min_delta=100)\n",
    "                mc = ModelCheckpoint('RQ4_LSTM_best_model.h5', monitor='val_mse', mode='min', verbose=1, save_best_only=True)\n",
    "                \n",
    "                start_time = time.time()\n",
    "                model.fit(trainX, trainY, epochs=100, batch_size=batch_size, verbose=1, validation_data=(valX, valY), callbacks=[es, mc])\n",
    "                training_time = time.time()-start_time\n",
    "                \n",
    "                saved_model = load_model('RQ4_LSTM_best_model.h5')\n",
    "                \n",
    "                trainPredict = saved_model.predict(trainX)\n",
    "                valPredict = saved_model.predict(valX)\n",
    "                testPredict = saved_model.predict(testX)\n",
    "                \n",
    "                trainScore = np.sqrt(mean_squared_error(trainY[:], trainPredict[:,0]))\n",
    "                valScore = np.sqrt(mean_squared_error(valY[:], valPredict[:,0]))\n",
    "                testScore = np.sqrt(mean_squared_error(testY[:], testPredict[:,0]))\n",
    "                testMAE = mean_absolute_error(testY[:], testPredict[:,0])\n",
    "                \n",
    "                saved_model.save('RQ4_LSTM_models/RQ4_LSTM_{}_L{}_N{}_B{}'.format(user, lookback_range, n, batch_size))\n",
    "                \n",
    "                out.append(round(training_time,4))\n",
    "                out.append(trainScore)\n",
    "                out.append(valScore)\n",
    "                out.append(testScore)\n",
    "                out.append(testMAE)\n",
    "                \n",
    "                if count == 0:\n",
    "                    cols.append('time_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('trainRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('valRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('testRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('testMAE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                with open('RQ4_LSTM_docu/RQ4_LSTM_{}.txt'.format(user), 'a') as docu_file:\n",
    "                    docu_file.write(\"L: {}, N: {}, B:{}, time:{}, train_score: {}, val_score: {}, test_score: {}, test_mae: {} \\n\".format(lookback_range, n, \n",
    "                                                                                                                            batch_size, \n",
    "                                                                                                                            training_time, \n",
    "                                                                                                                            trainScore, \n",
    "                                                                                                                            valScore, \n",
    "                                                                                                                            testScore, testMAE))\n",
    "                    \n",
    "    if count == 0:\n",
    "        df_out = pd.DataFrame(out).T\n",
    "        df_out.set_axis(cols, axis = 1, inplace = True)\n",
    "        count += 1\n",
    "    else:\n",
    "        df_out = pd.read_pickle('RQ4_LSTM_docu/df_results_RQ4_LSTM')\n",
    "        df_out.loc[len(df_out)] = out\n",
    "    df_out.to_pickle('RQ4_LSTM_docu/df_results_RQ4_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbf3a7-92f1-4b42-94e3-718c606a74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "cols = ['user', 'user_length', 'train_length', 'val_length', 'test_length']\n",
    "for user in lst_users1:\n",
    "    print(user)\n",
    "    out = [user]\n",
    "\n",
    "    dataframe = pd.read_pickle('Users_prepped/All/filtered/{}_final'.format(str(user)))\n",
    "    dataframe = dataframe[list(dataframe.columns)[1:]]\n",
    "    cols2 = [col for col in dataframe.columns if col != 'battery']\n",
    "    dataframe = dataframe[cols2]\n",
    "    dataset = dataframe.values\n",
    "    dataset = dataset.astype('float32')\n",
    "    \n",
    "    #Scale Features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    arrX = dataset[:, :-1]\n",
    "    arrY = dataset[:, -1]\n",
    "    arrY = arrY.reshape(arrY.shape[0], 1)\n",
    "    arrX = scaler.fit_transform(arrX)\n",
    "    dataset = np.concatenate((arrX, arrY), axis = 1)\n",
    "    \n",
    "    #split dataset\n",
    "    train_split, val_split = splits(dataset)\n",
    "    data_train = dataset[:train_split]\n",
    "    data_val = dataset[train_split:val_split]\n",
    "    data_test = dataset[val_split:]\n",
    "    \n",
    "    out.append(dataset.shape[0])\n",
    "    out.append(data_train.shape[0])\n",
    "    out.append(data_val.shape[0])\n",
    "    out.append(data_test.shape[0])\n",
    "    \n",
    "    if count == 0:\n",
    "        print(dataset.shape[0])\n",
    "        print(data_train.shape[0])\n",
    "        print(data_val.shape[0])\n",
    "        print(data_test.shape[0])\n",
    "    \n",
    "    for lookback_range in lookback_ranges:\n",
    "        #reshape into X=t and Y=t+1\n",
    "        trainX, trainY = create_dataset(data_train, lookback_range)\n",
    "        valX, valY = create_dataset(data_val, lookback_range)\n",
    "        testX, testY = create_dataset(data_test, lookback_range)\n",
    "        for n in neurons:\n",
    "            for batch_size in batch_sizes:\n",
    "                print('LookBack: {}, Neurons: {}, Batch_size:{}'.format(lookback_range, n, batch_size))\n",
    "                \n",
    "                model = Sequential()\n",
    "                model.add(GRU(n, input_shape=trainX.shape[1:], return_sequences = False, dropout =0.4))\n",
    "                model.add(Dense(1))\n",
    "                model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "                \n",
    "                es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, min_delta=100)\n",
    "                mc = ModelCheckpoint('RQ4_GRU_best_model.h5', monitor='val_mse', mode='min', verbose=1, save_best_only=True)\n",
    "                \n",
    "                start_time = time.time()\n",
    "                model.fit(trainX, trainY, epochs=100, batch_size=batch_size, verbose=1, validation_data=(valX, valY), callbacks=[es, mc])\n",
    "                training_time = time.time()-start_time\n",
    "                \n",
    "                saved_model = load_model('RQ4_GRU_best_model.h5')\n",
    "                \n",
    "                trainPredict = saved_model.predict(trainX)\n",
    "                valPredict = saved_model.predict(valX)\n",
    "                testPredict = saved_model.predict(testX)\n",
    "                \n",
    "                trainScore = np.sqrt(mean_squared_error(trainY[:], trainPredict[:,0]))\n",
    "                valScore = np.sqrt(mean_squared_error(valY[:], valPredict[:,0]))\n",
    "                testScore = np.sqrt(mean_squared_error(testY[:], testPredict[:,0]))\n",
    "                testMAE = mean_absolute_error(testY[:], testPredict[:,0])\n",
    "                \n",
    "                saved_model.save('RQ4_GRU_models/RQ4_GRU_{}_L{}_N{}_B{}'.format(user, lookback_range, n, batch_size))\n",
    "                \n",
    "                out.append(round(training_time,4))\n",
    "                out.append(trainScore)\n",
    "                out.append(valScore)\n",
    "                out.append(testScore)\n",
    "                out.append(testMAE)\n",
    "                \n",
    "                if count == 0:\n",
    "                    cols.append('time_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('trainRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('valRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('testRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('testMAE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                with open('RQ4_GRU_docu/RQ4_GRU_{}.txt'.format(user), 'a') as docu_file:\n",
    "                    docu_file.write(\"L: {}, N: {}, B:{}, time:{}, train_score: {}, val_score: {}, test_score: {}, test_mae: {} \\n\".format(lookback_range, n, \n",
    "                                                                                                                            batch_size, \n",
    "                                                                                                                            training_time, \n",
    "                                                                                                                            trainScore, \n",
    "                                                                                                                            valScore, \n",
    "                                                                                                                            testScore, testMAE))\n",
    "                    \n",
    "    if count == 0:\n",
    "        df_out = pd.DataFrame(out).T\n",
    "        df_out.set_axis(cols, axis = 1, inplace = True)\n",
    "        count += 1\n",
    "    else:\n",
    "        df_out = pd.read_pickle('RQ4_GRU_docu/df_results_RQ4_GRU')\n",
    "        df_out.loc[len(df_out)] = out\n",
    "    df_out.to_pickle('RQ4_GRU_docu/df_results_RQ4_GRU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
