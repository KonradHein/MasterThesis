{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6fc8e-5f76-4d60-8e43-d6003fbd3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef3936-f7cf-4fa5-9695-9b6e64a6c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_users = [25461, 24124, 24030, 24198, 15482, 15171, 23881, 24235, 23743,  \n",
    "              25169, 23875, 15441, 24007, 25569, 23754, 24192, 24041, 15530, \n",
    "              24109, 23768, 23883, 23921, 23769, 23889, 15110, 15373, 18001,  \n",
    "              15242, 24224, 23917, 25208, 24243, 25557, 15273, 23770, 23884,\n",
    "              24350, 23926, 23893, 15044, 23961, 24227, 23935, 23737, 23906,  \n",
    "              23982, 24121, 23909, 17984, 25498, 23738, 23985, 15170, 14995, \n",
    "              15115, 15510, 24127, 25175, 25170, 15419, 24324, 24197, 25163, \n",
    "              23955, 23740, 24348, 15205, 24343, 23837, 24206, 24079, 23872,\n",
    "              23871, 15208, 23756, 15729, 23829, 25502, 15280, 24196, 23914,\n",
    "              24470, 25235, 15270, 25172, 23745, 23899, 15304, 24203, 23984,  \n",
    "              15335, 15448, 15052, 15159, 24467, 24225, 15405, 25174, 25171,  \n",
    "              24213, 23822, 23876, 24232, 25197, 23988, 14981, 23753, 25180,\n",
    "              24039, 23800, 24204, 24248, 23913, 25250, 25178, 24212, 23833, \n",
    "              15024, 25167, 15382, 10599, 24125, 23995, 15187, 25201, 25227,\n",
    "              23900, 25203, 24223, 23953, 15209, 25275, 23981, 25176, 15462,\n",
    "              24120, 23924, 15173, 23936, 24349, 23915, 15363, 15277, 24226,  \n",
    "              23878, 15258, 24081, 24207, 23919, 15445, 25189, 15484, 24612,   \n",
    "              24249, 15444, 25207, 23767, 24033, 23898, 15588, 24071, 24122,\n",
    "              24087, 25278, 25547, 24346, 24199, 25504, 25164, 24040, 23785, \n",
    "              24185, 23787, 25522, 24461, 15051, 24193, 24167, 15151, 23867,\n",
    "              24246, 15031, 15241, 24083, 23897, 23983, 24195, 23778]\n",
    "lookback_ranges = [5, 10, 20]\n",
    "neurons = [64, 128, 256]\n",
    "batch_sizes = [64, 128, 256]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5d5b2-ab71-4893-a620-b7ce63da64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine split\n",
    "def splits(dataset):\n",
    "    instances_256 = len(dataset)/256\n",
    "    train_split = round(instances_256*0.8)*256\n",
    "    val_split = round(instances_256*0.9)*256\n",
    "    return train_split, val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac329f-d22a-4069-93fc-d5d3dc7b48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=5):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), :-1]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, -1])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801589cd-ad81-4431-a27d-183d20371187",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "cols = ['user', 'user_length', 'train_length', 'val_length', 'test_length']\n",
    "for user in lst_users1:\n",
    "    print(user)\n",
    "    out = [user]\n",
    "\n",
    "    dataframe = pd.read_pickle('Users_prepped/All/PerUser/{}_final'.format(str(user)))\n",
    "    dataframe = dataframe[list(dataframe.columns)[1:]]\n",
    "    dataset = dataframe.values\n",
    "    dataset = dataset.astype('float32')\n",
    "    \n",
    "    #Scale Features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    arrX = dataset[:, :-1]\n",
    "    arrY = dataset[:, -1]\n",
    "    arrY = arrY.reshape(arrY.shape[0], 1)\n",
    "    arrX = scaler.fit_transform(arrX)\n",
    "    dataset = np.concatenate((arrX, arrY), axis = 1)\n",
    "    \n",
    "    #split dataset\n",
    "    train_split, val_split = splits(dataset)\n",
    "    data_train = dataset[:train_split]\n",
    "    data_val = dataset[train_split:val_split]\n",
    "    data_test = dataset[val_split:]\n",
    "    \n",
    "    out.append(dataset.shape[0])\n",
    "    out.append(data_train.shape[0])\n",
    "    out.append(data_val.shape[0])\n",
    "    out.append(data_test.shape[0])\n",
    "    \n",
    "    if count == 0:\n",
    "        print(dataset.shape[0])\n",
    "        print(data_train.shape[0])\n",
    "        print(data_val.shape[0])\n",
    "        print(data_test.shape[0])\n",
    "    \n",
    "    for lookback_range in lookback_ranges:\n",
    "        #reshape into X=t and Y=t+1\n",
    "        trainX, trainY = create_dataset(data_train, lookback_range)\n",
    "        valX, valY = create_dataset(data_val, lookback_range)\n",
    "        testX, testY = create_dataset(data_test, lookback_range)\n",
    "        for n in neurons:\n",
    "            for batch_size in batch_sizes:\n",
    "                print('LookBack: {}, Neurons: {}, Batch_size:{}'.format(lookback_range, n, batch_size))\n",
    "                \n",
    "                model = Sequential()\n",
    "                model.add(LSTM(n, input_shape=trainX.shape[1:], return_sequences = False, dropout =0.4))\n",
    "                model.add(Dense(1))\n",
    "                model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "                \n",
    "                es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, min_delta=100)\n",
    "                mc = ModelCheckpoint('RQ1_LSTM_best_model.h5', monitor='val_mse', mode='min', verbose=1, save_best_only=True)\n",
    "                \n",
    "                start_time = time.time()\n",
    "                model.fit(trainX, trainY, epochs=100, batch_size=batch_size, verbose=1, validation_data=(valX, valY), callbacks=[es, mc])\n",
    "                training_time = time.time()-start_time\n",
    "                \n",
    "                saved_model = load_model('RQ1_LSTM_best_model.h5')\n",
    "                \n",
    "                trainPredict = saved_model.predict(trainX)\n",
    "                valPredict = saved_model.predict(valX)\n",
    "                testPredict = saved_model.predict(testX)\n",
    "                \n",
    "                trainScore = np.sqrt(mean_squared_error(trainY[:], trainPredict[:,0]))\n",
    "                valScore = np.sqrt(mean_squared_error(valY[:], valPredict[:,0]))\n",
    "                testScore = np.sqrt(mean_squared_error(testY[:], testPredict[:,0]))\n",
    "                testMAE = mean_absolute_error(testY[:], testPredict[:,0])\n",
    "                \n",
    "                saved_model.save('RQ1_LSTM_models/RQ1_LSTM_{}_L{}_N{}_B{}'.format(user, lookback_range, n, batch_size))\n",
    "                \n",
    "                out.append(round(training_time,4))\n",
    "                out.append(trainScore)\n",
    "                out.append(valScore)\n",
    "                out.append(testScore)\n",
    "                out.append(testMAE)\n",
    "                \n",
    "                if count == 0:\n",
    "                    cols.append('time_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('trainRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('valRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('testRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('testMAE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                with open('RQ1_LSTM_docu/RQ1_LSTM_{}.txt'.format(user), 'a') as docu_file:\n",
    "                    docu_file.write(\"L: {}, N: {}, B:{}, time:{}, train_score: {}, val_score: {}, test_score: {}, test_mae: {} \\n\".format(lookback_range, n, \n",
    "                                                                                                                            batch_size, \n",
    "                                                                                                                            training_time, \n",
    "                                                                                                                            trainScore, \n",
    "                                                                                                                            valScore, \n",
    "                                                                                                                            testScore, testMAE))\n",
    "                    \n",
    "    if count == 0:\n",
    "        df_out = pd.DataFrame(out).T\n",
    "        df_out.set_axis(cols, axis = 1, inplace = True)\n",
    "        count += 1\n",
    "    else:\n",
    "        df_out = pd.read_pickle('RQ1_LSTM_docu/df_results_RQ1_LSTM')\n",
    "        df_out.loc[len(df_out)] = out\n",
    "    df_out.to_pickle('RQ1_LSTM_docu/df_results_RQ1_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbf3a7-92f1-4b42-94e3-718c606a74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "cols = ['user', 'user_length', 'train_length', 'val_length', 'test_length']\n",
    "for user in lst_users1:\n",
    "    print(user)\n",
    "    out = [user]\n",
    "\n",
    "    dataframe = pd.read_pickle('Users_prepped/All/PerUser/{}_final'.format(str(user)))\n",
    "    dataframe = dataframe[list(dataframe.columns)[1:]]\n",
    "    dataset = dataframe.values\n",
    "    dataset = dataset.astype('float32')\n",
    "    \n",
    "    #Scale Features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    arrX = dataset[:, :-1]\n",
    "    arrY = dataset[:, -1]\n",
    "    arrY = arrY.reshape(arrY.shape[0], 1)\n",
    "    arrX = scaler.fit_transform(arrX)\n",
    "    dataset = np.concatenate((arrX, arrY), axis = 1)\n",
    "    \n",
    "    #split dataset\n",
    "    train_split, val_split = splits(dataset)\n",
    "    data_train = dataset[:train_split]\n",
    "    data_val = dataset[train_split:val_split]\n",
    "    data_test = dataset[val_split:]\n",
    "    \n",
    "    out.append(dataset.shape[0])\n",
    "    out.append(data_train.shape[0])\n",
    "    out.append(data_val.shape[0])\n",
    "    out.append(data_test.shape[0])\n",
    "    \n",
    "    if count == 0:\n",
    "        print(dataset.shape[0])\n",
    "        print(data_train.shape[0])\n",
    "        print(data_val.shape[0])\n",
    "        print(data_test.shape[0])\n",
    "    \n",
    "    for lookback_range in lookback_ranges:\n",
    "        #reshape into X=t and Y=t+1\n",
    "        trainX, trainY = create_dataset(data_train, lookback_range)\n",
    "        valX, valY = create_dataset(data_val, lookback_range)\n",
    "        testX, testY = create_dataset(data_test, lookback_range)\n",
    "        for n in neurons:\n",
    "            for batch_size in batch_sizes:\n",
    "                print('LookBack: {}, Neurons: {}, Batch_size:{}'.format(lookback_range, n, batch_size))\n",
    "                \n",
    "                model = Sequential()\n",
    "                model.add(GRU(n, input_shape=trainX.shape[1:], return_sequences = False, dropout =0.4))\n",
    "                model.add(Dense(1))\n",
    "                model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "                \n",
    "                es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, min_delta=100)\n",
    "                mc = ModelCheckpoint('RQ1_GRU_best_model.h5', monitor='val_mse', mode='min', verbose=1, save_best_only=True)\n",
    "                \n",
    "                start_time = time.time()\n",
    "                model.fit(trainX, trainY, epochs=100, batch_size=batch_size, verbose=1, validation_data=(valX, valY), callbacks=[es, mc])\n",
    "                training_time = time.time()-start_time\n",
    "                \n",
    "                saved_model = load_model('RQ1_GRU_best_model.h5')\n",
    "                \n",
    "                trainPredict = saved_model.predict(trainX)\n",
    "                valPredict = saved_model.predict(valX)\n",
    "                testPredict = saved_model.predict(testX)\n",
    "                \n",
    "                trainScore = np.sqrt(mean_squared_error(trainY[:], trainPredict[:,0]))\n",
    "                valScore = np.sqrt(mean_squared_error(valY[:], valPredict[:,0]))\n",
    "                testScore = np.sqrt(mean_squared_error(testY[:], testPredict[:,0]))\n",
    "                testMAE = mean_absolute_error(testY[:], testPredict[:,0])\n",
    "                \n",
    "                saved_model.save('RQ1_GRU_models/RQ1_GRU_{}_L{}_N{}_B{}'.format(user, lookback_range, n, batch_size))\n",
    "                \n",
    "                out.append(round(training_time,4))\n",
    "                out.append(trainScore)\n",
    "                out.append(valScore)\n",
    "                out.append(testScore)\n",
    "                out.append(testMAE)\n",
    "                \n",
    "                if count == 0:\n",
    "                    cols.append('time_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('trainRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('valRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('testRMSE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                    cols.append('testMAE_l{}_n{}_b{}'.format(lookback_range, n, batch_size))\n",
    "                with open('RQ1_GRU_docu/RQ1_GRU_{}.txt'.format(user), 'a') as docu_file:\n",
    "                    docu_file.write(\"L: {}, N: {}, B:{}, time:{}, train_score: {}, val_score: {}, test_score: {}, test_mae: {} \\n\".format(lookback_range, n, \n",
    "                                                                                                                            batch_size, \n",
    "                                                                                                                            training_time, \n",
    "                                                                                                                            trainScore, \n",
    "                                                                                                                            valScore, \n",
    "                                                                                                                            testScore, testMAE))\n",
    "                    \n",
    "    if count == 0:\n",
    "        df_out = pd.DataFrame(out).T\n",
    "        df_out.set_axis(cols, axis = 1, inplace = True)\n",
    "        count += 1\n",
    "    else:\n",
    "        df_out = pd.read_pickle('RQ1_GRU_docu/df_results_RQ1_GRU')\n",
    "        df_out.loc[len(df_out)] = out\n",
    "    df_out.to_pickle('RQ1_GRU_docu/df_results_RQ1_GRU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
